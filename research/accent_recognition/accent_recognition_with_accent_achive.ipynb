{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"accent_recognition_with_accent_achive.ipynb","provenance":[],"collapsed_sections":["0qMdHyA3tGZt"],"mount_file_id":"124FS6CuCuibdh0RNZjEUMyrSEAwyuMNA","authorship_tag":"ABX9TyM+aYX/frMX0SNp8R0/gZRy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"id":"fURJ4rWZrcsN","executionInfo":{"status":"ok","timestamp":1652357597540,"user_tz":-180,"elapsed":258,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"outputs":[],"source":["import requests\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","import time\n","import sys\n","import re\n","import os\n","from os import listdir\n","import matplotlib.pyplot as plt\n","from os.path import isfile, join\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","import librosa\n","import librosa.display\n","\n","import cv2\n","import zipfile\n","from PIL import Image\n","\n","import time\n","import copy"]},{"cell_type":"markdown","source":["# Get accent archive"],"metadata":{"id":"0qMdHyA3tGZt"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/NIS_2022/accent_archive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jGlbWQEgskVq","executionInfo":{"status":"ok","timestamp":1652304487220,"user_tz":-180,"elapsed":231,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"96757cc5-a44e-45c2-9a94-d19873ff45b9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NIS_2022/accent_archive\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/akshanshchaudhry/Speech-Accent-Recognition.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xa5D3Zs0uuUK","executionInfo":{"status":"ok","timestamp":1652299664209,"user_tz":-180,"elapsed":1575,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"fea68b80-ab25-4147-aa37-5b7d9879ce9d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Speech-Accent-Recognition'...\n","remote: Enumerating objects: 21, done.\u001b[K\n","remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n","Unpacking objects: 100% (21/21), done.\n"]}]},{"cell_type":"code","source":["!pip install pydub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k2YCf4AB-RED","executionInfo":{"status":"ok","timestamp":1652303707343,"user_tz":-180,"elapsed":4253,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"595609c4-4f71-4fe5-c009-3f27375b3f81"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}]},{"cell_type":"code","source":["%cd ../Speech-Accent-Recognition/src"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRod64nNvAPF","executionInfo":{"status":"ok","timestamp":1652307944317,"user_tz":-180,"elapsed":231,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"3d326926-a9ee-4380-e665-57d47ee33b9f"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NIS_2022/accent_archive/Speech-Accent-Recognition/src\n"]}]},{"cell_type":"code","source":["!python fromwebsite.py /content/drive/MyDrive/NIS_2022/accent_archive/data/bio_metadata.csv  chinese english russian japanese arabic spanish korean"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sbu4KwUrvIjZ","executionInfo":{"status":"ok","timestamp":1652307292681,"user_tz":-180,"elapsed":64655,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"ef27687d-d86b-488f-8889-e0a107dbda78"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading from http://accent.gmu.edu/browse_language.php?function=find&language=japanese\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=221\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=222\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=223\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=224\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=225\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=226\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=227\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=486\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=543\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=827\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1046\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1365\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1381\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1382\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1521\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1537\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1610\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1626\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1684\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1833\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1847\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1881\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1942\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1948\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1987\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=1991\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2123\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2390\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2436\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2492\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2493\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2547\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2555\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2567\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2723\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2797\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2807\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2826\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2843\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2850\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2866\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2940\n","downloading from http://accent.gmu.edu/browse_language.php?function=detail&speakerid=2953\n","loading finished\n"]}]},{"cell_type":"code","source":["df = pd.read_csv ('/content/drive/MyDrive/NIS_2022/accent_archive/data/processed_bio_metadata.csv',\n","                  sep='\\t')"],"metadata":{"id":"NaggCqcpGUBx","executionInfo":{"status":"ok","timestamp":1652309317836,"user_tz":-180,"elapsed":210,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["categories = []\n","for index, row in df.iterrows():\n","    category = 'default'\n","    if 'china' in row['birth_place'] or 'taiwan' in row['birth_place']:\n","        category = 'chinese'\n","    elif 'english' in row['language_num']:\n","        if 'usa' in row['birth_place']:\n","            category = 'usa'\n","        elif 'uk' in row['birth_place']:\n","            category = 'uk'\n","        elif 'canada' in row['birth_place']:\n","            category = 'canada'\n","        elif 'australia' in row['birth_place']:\n","            category = 'australia'\n","    elif 'russian' in row['language_num']:\n","        category = 'russian'\n","    elif 'arabic' in row['language_num']:\n","        category = 'arabic'\n","    elif 'spanish' in row['language_num']:\n","        category = 'spanish'\n","    elif 'korean' in row['language_num']:\n","        category = 'korean'\n","    elif 'japanese' in row['language_num']:\n","        category = 'japanese'\n","    categories.append(category)\n","    "],"metadata":{"id":"zzS02fvxGZN7","executionInfo":{"status":"ok","timestamp":1652308586694,"user_tz":-180,"elapsed":362,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["df['category'] = categories"],"metadata":{"id":"a8g8GgRxMrrD","executionInfo":{"status":"ok","timestamp":1652309034302,"user_tz":-180,"elapsed":219,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["len(categories)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HXVudKZcQ69f","executionInfo":{"status":"ok","timestamp":1652309036200,"user_tz":-180,"elapsed":221,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"e19ddbcb-3920-4a4b-b878-8438d550b239"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1521"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["df.to_csv(r'/content/drive/MyDrive/NIS_2022/accent_archive/data/processed_bio_metadata.csv', index=False, sep='\\t', header='true')"],"metadata":{"id":"UNQgumH5M7ie","executionInfo":{"status":"ok","timestamp":1652309047522,"user_tz":-180,"elapsed":216,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["!python getaudio.py /content/drive/MyDrive/NIS_2022/accent_archive/data/processed_bio_metadata.csv"],"metadata":{"id":"2y9IzcHcvORp","executionInfo":{"status":"ok","timestamp":1652310231897,"user_tz":-180,"elapsed":679709,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":["# Dataset create"],"metadata":{"id":"MmH7lUMyYNh_"}},{"cell_type":"code","source":["def get_melspectrogram_db(file_path, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n","    path = os.fspath(file_path)\n","    wav,sr = librosa.load(path,sr=sr)\n","    # if wav.shape[0]<5*sr:\n","    #     wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n","    # else:\n","    #     wav=wav[:5*sr]\n","    spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft,\n","                hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n","    spec_db=librosa.power_to_db(spec,top_db=top_db)\n","    return spec_db\n","\n","\n","def spec_to_image(spec, eps=1e-6):\n","    mean = spec.mean()\n","    std = spec.std()\n","    spec_norm = (spec - mean) / (std + eps)\n","    spec_min, spec_max = spec_norm.min(), spec_norm.max()\n","    spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n","    spec_scaled = spec_scaled.astype(np.uint8)\n","    return spec_scaled"],"metadata":{"id":"wAOgV3kxGdvv","executionInfo":{"status":"ok","timestamp":1652356535633,"user_tz":-180,"elapsed":239,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["audio_dir = '/content/drive/MyDrive/NIS_2022/accent_archive/data/audio/'\n","mel_spectrograms_dir = '/content/drive/MyDrive/NIS_2022/accent_archive/data/mel_spectrograms/'\n","\n","train_dir = mel_spectrograms_dir + 'train'\n","valid_dir = mel_spectrograms_dir + 'validation'"],"metadata":{"id":"Ng5p8wYcYMu-","executionInfo":{"status":"ok","timestamp":1652356535994,"user_tz":-180,"elapsed":1,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["for subdir, dirs, files in os.walk(audio_dir):\n","    if len(files) == 0: \n","        continue\n","    accent = os.path.basename(subdir)\n","    train, test = train_test_split(files, test_size=0.2)\n","    for audio_file in train:\n","        audio_path = os.path.join(subdir, audio_file)\n","        try:\n","          melspectrogram = spec_to_image(get_melspectrogram_db(audio_path))\n","        except:\n","            continue\n","        img = Image.fromarray(melspectrogram)\n","        save_path = train_dir + '/' + accent\n","        if not os.path.exists(save_path):\n","            os.makedirs(save_path)\n","        img.save(save_path+'/'+os.path.splitext(os.path.basename(audio_path))[0]+'.png')\n","\n","    for audio_file in test:\n","        audio_path = os.path.join(subdir, audio_file)\n","        try:\n","          melspectrogram = spec_to_image(get_melspectrogram_db(audio_path))\n","        except:\n","            continue\n","        img = Image.fromarray(melspectrogram)\n","        save_path = valid_dir + '/' + accent\n","        if not os.path.exists(save_path):\n","            os.makedirs(save_path)\n","        img.save(save_path+'/'+os.path.splitext(os.path.basename(audio_path))[0]+'.png')"],"metadata":{"id":"7qGS5Qgf-arB","executionInfo":{"status":"ok","timestamp":1652357009338,"user_tz":-180,"elapsed":390760,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Data loading"],"metadata":{"id":"l5fQQ4SBI6Fl"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset\n","import torchaudio\n","\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","\n","import torchvision.models as models"],"metadata":{"id":"9arBNb2EFZUV","executionInfo":{"status":"ok","timestamp":1652357218124,"user_tz":-180,"elapsed":3885,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["input_size = 224\n","batch_size = 8"],"metadata":{"id":"sreTI7uxJQlI","executionInfo":{"status":"ok","timestamp":1652364213458,"user_tz":-180,"elapsed":273,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":253,"outputs":[]},{"cell_type":"code","source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(input_size),\n","        # transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'validation': transforms.Compose([\n","        transforms.Resize(input_size),\n","        transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","mel_spectrograms_dir = '/content/drive/MyDrive/NIS_2022/accent_archive/data/mel_spectrograms/'\n","image_datasets = {x: ImageFolder(os.path.join(mel_spectrograms_dir, x), data_transforms[x]) for x in ['train', 'validation']}"],"metadata":{"id":"mwvS0KiBKjeO","executionInfo":{"status":"ok","timestamp":1652364213729,"user_tz":-180,"elapsed":1,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":254,"outputs":[]},{"cell_type":"code","source":["def make_weights_for_balanced_classes(images, nclasses):                        \n","    count = [0] * nclasses                                                      \n","    for item in images:                                                         \n","        count[item[1]] += 1                                                     \n","    weight_per_class = [0.] * nclasses                                      \n","    N = float(sum(count))                                                   \n","    for i in range(nclasses):                                                   \n","        weight_per_class[i] = N/float(count[i])                                 \n","    weight = [0] * len(images)                                              \n","    for idx, val in enumerate(images):                                          \n","        weight[idx] = weight_per_class[val[1]]                                  \n","    return weight                         "],"metadata":{"id":"kxESM7o6YGQw","executionInfo":{"status":"ok","timestamp":1652364213730,"user_tz":-180,"elapsed":2,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":255,"outputs":[]},{"cell_type":"code","source":["# weights = make_weights_for_balanced_classes(image_datasets['train'].imgs, len(image_datasets['train'].classes))                                                                \n","# weights = torch.DoubleTensor(weights)                                       \n","# sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights)) "],"metadata":{"id":"QxspKCU5XEYN","executionInfo":{"status":"ok","timestamp":1652364214617,"user_tz":-180,"elapsed":1,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":256,"outputs":[]},{"cell_type":"code","source":["# dataloaders_dict = {}\n","# dataloaders_dict['train'] = torch.utils.data.DataLoader(image_datasets['train'], \n","#                                                    batch_size=batch_size, \n","#                                                   #  shuffle=True, \n","#                                                    sampler=sampler,\n","#                                                    num_workers=4) "],"metadata":{"id":"Sexc2S2qYWJl","executionInfo":{"status":"ok","timestamp":1652364214971,"user_tz":-180,"elapsed":2,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":257,"outputs":[]},{"cell_type":"code","source":["# dataloaders_dict['validation'] = torch.utils.data.DataLoader(image_datasets['validation'], \n","#                                                    batch_size=batch_size, \n","#                                                    shuffle=True, \n","#                                                    num_workers=4) "],"metadata":{"id":"JGpYiMgRYm-K","executionInfo":{"status":"ok","timestamp":1652364214971,"user_tz":-180,"elapsed":2,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":258,"outputs":[]},{"cell_type":"code","source":["dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], \n","                                                   batch_size=batch_size, \n","                                                   shuffle=True, \n","                                                   num_workers=4) for x in ['train', 'validation']}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NaDTNFxdXG1d","executionInfo":{"status":"ok","timestamp":1652364215236,"user_tz":-180,"elapsed":2,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"963e9d26-d456-4942-9b83-f79305e71c79"},"execution_count":259,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["num_classes = 10\n","num_epochs = 15"],"metadata":{"id":"cG8TrenYK398","executionInfo":{"status":"ok","timestamp":1652364215237,"user_tz":-180,"elapsed":2,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":260,"outputs":[]},{"cell_type":"code","source":["resnet18_pretrained = models.resnet18(pretrained=True)\n","resnet18_pretrained.fc = nn.Linear(512, num_classes)"],"metadata":{"id":"FPB3XhTnLtnV","executionInfo":{"status":"ok","timestamp":1652364215928,"user_tz":-180,"elapsed":334,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":261,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3kUxNgYEL8PR","executionInfo":{"status":"ok","timestamp":1652364216252,"user_tz":-180,"elapsed":1,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"810edfc6-85b7-4468-b146-dccaaebb0a84"},"execution_count":262,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'validation']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'validation' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'validation':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"],"metadata":{"id":"1Urx0kmrLvp2","executionInfo":{"status":"ok","timestamp":1652364216644,"user_tz":-180,"elapsed":3,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":263,"outputs":[]},{"cell_type":"code","source":["resnet18_pretrained = resnet18_pretrained.to(device)\n","\n","params_to_update = resnet18_pretrained.parameters()\n","optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"],"metadata":{"id":"uZ9nVFpDMEoK","executionInfo":{"status":"ok","timestamp":1652364217041,"user_tz":-180,"elapsed":5,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":264,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","# Train and evaluate\n","resnet18_pretrained, hist = train_model(resnet18_pretrained,\n","                             dataloaders_dict,\n","                             criterion, optimizer_ft, \n","                             num_epochs=num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gSfsTs2_MmNk","executionInfo":{"status":"ok","timestamp":1652364437071,"user_tz":-180,"elapsed":219145,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"097061c6-475f-4113-f8cc-acd87c4974dc"},"execution_count":265,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/14\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 2.0793 Acc: 0.2935\n","validation Loss: 1.9866 Acc: 0.3503\n","\n","Epoch 1/14\n","----------\n","train Loss: 1.6154 Acc: 0.4606\n","validation Loss: 2.4215 Acc: 0.2347\n","\n","Epoch 2/14\n","----------\n","train Loss: 1.1575 Acc: 0.6234\n","validation Loss: 2.2836 Acc: 0.3265\n","\n","Epoch 3/14\n","----------\n","train Loss: 0.7123 Acc: 0.7818\n","validation Loss: 2.2637 Acc: 0.3571\n","\n","Epoch 4/14\n","----------\n","train Loss: 0.4234 Acc: 0.8935\n","validation Loss: 2.5840 Acc: 0.3605\n","\n","Epoch 5/14\n","----------\n","train Loss: 0.2250 Acc: 0.9498\n","validation Loss: 2.6697 Acc: 0.3265\n","\n","Epoch 6/14\n","----------\n","train Loss: 0.2189 Acc: 0.9429\n","validation Loss: 2.9263 Acc: 0.3231\n","\n","Epoch 7/14\n","----------\n","train Loss: 0.1858 Acc: 0.9506\n","validation Loss: 2.5619 Acc: 0.3129\n","\n","Epoch 8/14\n","----------\n","train Loss: 0.1853 Acc: 0.9576\n","validation Loss: 2.8874 Acc: 0.3401\n","\n","Epoch 9/14\n","----------\n","train Loss: 0.1916 Acc: 0.9446\n","validation Loss: 2.7654 Acc: 0.3571\n","\n","Epoch 10/14\n","----------\n","train Loss: 0.1346 Acc: 0.9714\n","validation Loss: 2.8042 Acc: 0.3537\n","\n","Epoch 11/14\n","----------\n","train Loss: 0.1127 Acc: 0.9688\n","validation Loss: 2.7641 Acc: 0.3707\n","\n","Epoch 12/14\n","----------\n","train Loss: 0.0708 Acc: 0.9844\n","validation Loss: 2.8928 Acc: 0.3299\n","\n","Epoch 13/14\n","----------\n","train Loss: 0.0786 Acc: 0.9766\n","validation Loss: 2.8061 Acc: 0.3707\n","\n","Epoch 14/14\n","----------\n","train Loss: 0.1003 Acc: 0.9732\n","validation Loss: 2.8038 Acc: 0.3469\n","\n","Training complete in 3m 39s\n","Best val Acc: 0.370748\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","from itertools import chain\n","\n","y_pred_list = []\n","y_labels_list = []\n","resnet18_pretrained.eval()\n","with torch.no_grad():\n","    for batch in dataloaders_dict['validation']:\n","        images, labels = batch\n","        y_labels_list.append(labels.numpy())\n","        images, _ = images.cuda(), labels.cuda()\n","        y_test_pred = resnet18_pretrained(images)\n","        y_pred_softmax = torch.log_softmax(y_test_pred, dim = 1)\n","        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1) \n","        y_pred_list.append([x for x in y_pred_tags.cpu().numpy()])\n","\n","y_pred_list = list(chain.from_iterable(y_pred_list))\n","y_labels_list = list(chain.from_iterable(y_labels_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDWSygtzMpRw","executionInfo":{"status":"ok","timestamp":1652364442374,"user_tz":-180,"elapsed":5313,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"0eed8c36-ec74-4943-8bfb-45459284e944"},"execution_count":266,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["print(classification_report(y_labels_list, y_pred_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YEdFVc6M32O","executionInfo":{"status":"ok","timestamp":1652364442374,"user_tz":-180,"elapsed":38,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"f1d12250-d96b-452b-b33e-ba6835fe42e6"},"execution_count":267,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.19      0.17      0.18        40\n","           1       0.00      0.00      0.00         9\n","           2       0.00      0.00      0.00        10\n","           3       0.52      0.33      0.40        43\n","           4       0.00      0.00      0.00         9\n","           5       0.20      0.15      0.17        20\n","           6       0.00      0.00      0.00        17\n","           7       0.29      0.49      0.36        47\n","           8       0.00      0.00      0.00        14\n","           9       0.50      0.73      0.59        85\n","\n","    accuracy                           0.37       294\n","   macro avg       0.17      0.19      0.17       294\n","weighted avg       0.30      0.37      0.32       294\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["confusion_matrix(y_labels_list, y_pred_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4v-fCHu1ON_V","executionInfo":{"status":"ok","timestamp":1652364442375,"user_tz":-180,"elapsed":33,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"2fe606a7-1997-4cd7-aefa-55f243669921"},"execution_count":268,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 7,  0,  0,  3,  0,  4,  1, 15,  0, 10],\n","       [ 2,  0,  0,  0,  0,  1,  0,  2,  0,  4],\n","       [ 0,  0,  0,  0,  0,  0,  0,  2,  0,  8],\n","       [ 7,  0,  0, 14,  1,  3,  0, 12,  0,  6],\n","       [ 0,  0,  0,  2,  0,  1,  1,  3,  0,  2],\n","       [ 3,  0,  1,  1,  0,  3,  0,  3,  0,  9],\n","       [ 1,  0,  1,  0,  0,  0,  0,  7,  0,  8],\n","       [ 4,  1,  1,  4,  0,  0,  1, 23,  0, 13],\n","       [ 3,  0,  0,  0,  0,  1,  1,  6,  0,  3],\n","       [10,  0,  1,  3,  0,  2,  0,  7,  0, 62]])"]},"metadata":{},"execution_count":268}]},{"cell_type":"code","source":["dataloaders_dict['train'].dataset.classes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"asiZtSPaOZGV","executionInfo":{"status":"ok","timestamp":1652364442375,"user_tz":-180,"elapsed":21,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}},"outputId":"b232e772-f2fc-4520-cdf2-cde3f0961c74"},"execution_count":269,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['arabic',\n"," 'australia',\n"," 'canada',\n"," 'chinese',\n"," 'japanese',\n"," 'korean',\n"," 'russian',\n"," 'spanish',\n"," 'uk',\n"," 'usa']"]},"metadata":{},"execution_count":269}]},{"cell_type":"code","source":[""],"metadata":{"id":"Coxwuoe6VwXg","executionInfo":{"status":"ok","timestamp":1652364442375,"user_tz":-180,"elapsed":19,"user":{"displayName":"Polina Smolnikova","userId":"01669568308474740016"}}},"execution_count":269,"outputs":[]}]}